# -*- coding: utf-8 -*-
"""M24CSA027_M24CSA028_M24CSA029_DIA_PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1njkInhbnTG2teeEhI0Xu3A-J03LfHIqv

**Project Title: Comparative Study of Lossy Image Compression Techniques**

**Submitted By :**

**Project ID-9**
*   Ratnesh Dubey (M24CSA027)
*   Ritul Jangir (M24CSA028)
*   Shivani Tiwari (M24CSA029)
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install PyWavelets

# Import libraries
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import pywt
import os
import glob
import time
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr
from scipy.fftpack import dct, idct

"""RESEARCH PAPER REFERENCES:

[1] Wallace, G.K., "The JPEG still picture compression standard",
    IEEE Transactions on Consumer Electronics, vol. 38, no. 1, pp. 18-34, 1992.
    
[2] Antonini, M., et al., "Image coding using wavelet transform",
    IEEE Transactions on Image Processing, vol. 1, no. 2, pp. 205-220, 1992.
    
[3] Wang, Z., et al., "Image quality assessment: from error visibility to structural similarity",
    IEEE Transactions on Image Processing, vol. 13, no. 4, pp. 600-612, 2004.
    
[4] Pennebaker, W.B. and Mitchell, J.L., "JPEG: Still image data compression standard",
    Van Nostrand Reinhold, 1992.
    
[5] Shapiro, J.M., "Embedded image coding using zerotrees of wavelet coefficients",
    IEEE Transactions on Signal Processing, vol. 41, no. 12, pp. 3445-3462, 1993.
"""

# : Helper functions
def load_image(path):
    img = Image.open(path).convert('L')
    return np.array(img)

def calculate_metrics(original, compressed):
    original = original.astype(np.float32)
    compressed = compressed.astype(np.float32)
    psnr_value = psnr(original, compressed, data_range=255.0)
    ssim_value = ssim(original, compressed, data_range=255.0)
    return psnr_value, ssim_value

def show_images(images, titles):
    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))
    for i, (img, title) in enumerate(zip(images, titles)):
        axes[i].imshow(img, cmap='gray')
        axes[i].set_title(title)
        axes[i].axis('off')
    plt.tight_layout()
    plt.show()

#  Standard JPEG Quantization Matrix
def get_jpeg_quantization_matrix(quality):
    Q = np.array([
        [16, 11, 10, 16, 24, 40, 51, 61],
        [12, 12, 14, 19, 26, 58, 60, 55],
        [14, 13, 16, 24, 40, 57, 69, 56],
        [14, 17, 22, 29, 51, 87, 80, 62],
        [18, 22, 37, 56, 68, 109, 103, 77],
        [24, 35, 55, 64, 81, 104, 113, 92],
        [49, 64, 78, 87, 103, 121, 120, 101],
        [72, 92, 95, 98, 112, 100, 103, 99]
    ])

    # Convert 1-100 quality to JPEG scaling factor
    if quality < 50:
        scale = 5000 / quality
    else:
        scale = 200 - quality * 2

    # Scale and clip the matrix
    Q = np.clip(np.round((Q * scale) / 100.0), 1, 255).astype(np.float32)

    return Q

# Perceptual DCT-based Compression
def dct_compression(image, quality_factor=50, perceptual=True):
    start_time = time.time()

    # Ensure image dimensions are multiples of 8
    h, w = image.shape
    h_pad, w_pad = h + (8 - h % 8) % 8, w + (8 - w % 8) % 8
    padded = np.zeros((h_pad, w_pad))
    padded[:h, :w] = image

    # Prepare for DCT processing in 8x8 blocks
    result = np.zeros_like(padded)

    # Create quantization matrix
    if perceptual:
        Q = get_jpeg_quantization_matrix(quality_factor)
    else:
        Q = np.ones((8, 8))
        for i in range(8):
            for j in range(8):
                Q[i, j] = 1 + (i + j) * (100 - quality_factor) / 10

    # Process 8x8 blocks
    nonzero_count = 0
    total_count = 0

    for i in range(0, h_pad, 8):
        for j in range(0, w_pad, 8):
            block = padded[i:i+8, j:j+8] - 128
            dct_block = dct(dct(block.T, norm='ortho').T, norm='ortho')
            quantized = np.round(dct_block / Q)
            nonzero_count += np.count_nonzero(quantized)
            total_count += 64

            # Dequantize
            dequantized = quantized * Q
            idct_block = idct(idct(dequantized.T, norm='ortho').T, norm='ortho')
            result[i:i+8, j:j+8] = idct_block + 128

    # Calculate compression ratio
    compression_ratio = total_count / max(nonzero_count, 1)
    result = np.clip(result[:h, :w], 0, 255)
    execution_time = time.time() - start_time
    return result, compression_ratio, execution_time

#  Advanced Wavelet-based Compression
def wavelet_compression(image, threshold_percent=10, wavelet='haar'):
    start_time = time.time()
    coeffs = pywt.wavedec2(image, wavelet, level=3)
    coeffs_modified = [coeffs[0].copy()]
    all_coeffs = []
    for detail_coeffs in coeffs[1:]:
        for detail in detail_coeffs:
            all_coeffs.append(detail.flatten())
    all_coeffs = np.concatenate(all_coeffs) if all_coeffs else np.array([])

    # Calculate threshold and coefficient counts
    threshold = np.percentile(np.abs(all_coeffs), 100 - threshold_percent)
    total_coeffs = coeffs[0].size
    nonzero_before = np.count_nonzero(coeffs[0])

    for detail_coeffs in coeffs[1:]:
        for detail in detail_coeffs:
            total_coeffs += detail.size
            nonzero_before += np.count_nonzero(detail)

    # Apply thresholding to detail coefficients
    for i in range(1, len(coeffs)):
        coeffs_modified.append([])
        for detail_coeff in coeffs[i]:
            thresholded = detail_coeff.copy()
            thresholded[np.abs(thresholded) < threshold] = 0
            coeffs_modified[i].append(thresholded)

    # Count non-zero coefficients after thresholding
    nonzero_after = np.count_nonzero(coeffs_modified[0])
    for i in range(1, len(coeffs_modified)):
        for detail_coeff in coeffs_modified[i]:
            nonzero_after += np.count_nonzero(detail_coeff)

    # Reconstruct image and calculate compression ratio
    reconstructed = pywt.waverec2(coeffs_modified, wavelet)
    reconstructed = reconstructed[:image.shape[0], :image.shape[1]]
    reconstructed = np.clip(reconstructed, 0, 255)
    compression_ratio = total_coeffs / max(nonzero_after, 1)
    execution_time = time.time() - start_time
    return reconstructed, compression_ratio, execution_time

# Subjective Quality Assessment
def subjective_quality_score(original, compressed):
    psnr_val, ssim_val = calculate_metrics(original, compressed)
    if psnr_val > 40 and ssim_val > 0.97:
        score = 5  # Excellent
        category = "Excellent - No visible compression artifacts"
    elif psnr_val > 35 and ssim_val > 0.94:
        score = 4  # Good
        category = "Good - Compression artifacts not noticeable in normal viewing"
    elif psnr_val > 30 and ssim_val > 0.90:
        score = 3  # Fair
        category = "Fair - Minor artifacts visible upon close inspection"
    elif psnr_val > 25 and ssim_val > 0.80:
        score = 2  # Poor
        category = "Poor - Visible artifacts affecting viewing experience"
    else:
        score = 1  # Bad
        category = "Bad - Severe artifacts significantly degrading image quality"

    return score, category

# Compression Experiment with Extended Analysis
def experiment_compression_quality(image_path, quality_range, method='dct', perceptual=True, wavelet_type='haar'):

    image = load_image(image_path)
    results = {
        'compression_ratio': [],
        'psnr': [],
        'ssim': [],
        'execution_time': [],
        'subjective_score': [],
        'quality_category': []
    }

    print(f"\n{method.upper()} Compression Analysis{'with Perceptual Quantization' if method == 'dct' and perceptual else ''}:")
    print("-" * 80)
    print(f"{'Quality':<10} {'Ratio':<8} {'PSNR (dB)':<10} {'SSIM':<8} {'Time (ms)':<10} {'Subj. Score':<12} {'Category'}")
    print("-" * 80)

    for quality in quality_range:
        if method == 'dct':
            compressed, ratio, exec_time = dct_compression(image, quality_factor=quality, perceptual=perceptual)
        else:
            compressed, ratio, exec_time = wavelet_compression(image, threshold_percent=quality, wavelet=wavelet_type)

        # Calculate objective metrics
        psnr_val, ssim_val = calculate_metrics(image, compressed)

        # Calculate subjective score
        subj_score, category = subjective_quality_score(image, compressed)

        # Store results
        results['compression_ratio'].append(ratio)
        results['psnr'].append(psnr_val)
        results['ssim'].append(ssim_val)
        results['execution_time'].append(exec_time)
        results['subjective_score'].append(subj_score)
        results['quality_category'].append(category)

        print(f"{quality:<10} {ratio:<8.2f} {psnr_val:<10.2f} {ssim_val:<8.4f} {exec_time*1000:<10.2f} {subj_score:<12} {category}")

    print("-" * 80)
    return results

# Advanced Visualization Functions
def plot_comparison(dct_results, wavelet_results, metric='psnr', title_suffix=""):
    plt.figure(figsize=(10, 6))
    plt.plot(dct_results['compression_ratio'], dct_results[metric], 'o-', label='DCT (JPEG-like)')
    plt.plot(wavelet_results['compression_ratio'], wavelet_results[metric], 's-', label='Wavelet (JPEG2000-like)')

    if metric in ['psnr', 'ssim']:
        plt.xlabel('Compression Ratio')
        plt.ylabel(metric.upper())
        plt.title(f'Compression Ratio vs {metric.upper()} {title_suffix}')
    elif metric == 'execution_time':
        plt.xlabel('Compression Ratio')
        plt.ylabel('Execution Time (ms)')
        plt.title(f'Compression Ratio vs Execution Time {title_suffix}')
    elif metric == 'subjective_score':
        plt.xlabel('Compression Ratio')
        plt.ylabel('Subjective Quality Score (1-5)')
        plt.title(f'Compression Ratio vs Subjective Quality {title_suffix}')

    plt.legend()
    plt.grid(True)
    plt.show()

def visualize_compression_artifacts(image_path, dct_quality=50, wavelet_threshold=10, zoom_region=None):
    original = load_image(image_path)
    dct_compressed, dct_ratio, _ = dct_compression(original, quality_factor=dct_quality, perceptual=True)
    wavelet_compressed, wav_ratio, _ = wavelet_compression(original, threshold_percent=wavelet_threshold)

    # Calculate metrics
    dct_psnr, dct_ssim = calculate_metrics(original, dct_compressed)
    wav_psnr, wav_ssim = calculate_metrics(original, wavelet_compressed)
    if zoom_region is None:
        h, w = original.shape
        center_x, center_y = w // 2, h // 2
        zoom_width, zoom_height = min(100, w // 4), min(100, h // 4)
        zoom_region = (center_x - zoom_width // 2, center_y - zoom_height // 2, zoom_width, zoom_height)

    x, y, width, height = zoom_region

    # Extract zoom regions
    original_zoom = original[y:y+height, x:x+width]
    dct_zoom = dct_compressed[y:y+height, x:x+width]
    wavelet_zoom = wavelet_compressed[y:y+height, x:x+width]

    # Show full images
    plt.figure(figsize=(15, 10))
    plt.subplot(231)
    plt.imshow(original, cmap='gray')
    plt.title('Original')
    plt.gca().add_patch(plt.Rectangle((x, y), width, height, edgecolor='r', facecolor='none'))

    plt.subplot(232)
    plt.imshow(dct_compressed, cmap='gray')
    plt.title(f'DCT (CR: {dct_ratio:.2f}, PSNR: {dct_psnr:.2f})')
    plt.gca().add_patch(plt.Rectangle((x, y), width, height, edgecolor='r', facecolor='none'))

    plt.subplot(233)
    plt.imshow(wavelet_compressed, cmap='gray')
    plt.title(f'Wavelet (CR: {wav_ratio:.2f}, PSNR: {wav_psnr:.2f})')
    plt.gca().add_patch(plt.Rectangle((x, y), width, height, edgecolor='r', facecolor='none'))

    # Show zoomed regions
    plt.subplot(234)
    plt.imshow(original_zoom, cmap='gray')
    plt.title('Original (Zoom)')

    plt.subplot(235)
    plt.imshow(dct_zoom, cmap='gray')
    plt.title('DCT (Zoom)')

    plt.subplot(236)
    plt.imshow(wavelet_zoom, cmap='gray')
    plt.title('Wavelet (Zoom)')

    plt.tight_layout()
    plt.show()

    # Add analysis of artifact types
    print("Compression Artifact Analysis:")
    print("-" * 50)
    print(f"DCT (JPEG-like) - Compression Ratio: {dct_ratio:.2f}")
    print(f"- PSNR: {dct_psnr:.2f} dB, SSIM: {dct_ssim:.4f}")
    print("- Typical artifacts: Block boundaries, ringing around edges, loss of fine details")
    print()
    print(f"Wavelet - Compression Ratio: {wav_ratio:.2f}")
    print(f"- PSNR: {wav_psnr:.2f} dB, SSIM: {wav_ssim:.4f}")
    print("- Typical artifacts: Blurring, ringing around edges, less visible block artifacts")
    print("-" * 50)

# Process Single Image with Extended Analysis
def process_single_image_extended(image_path):
    image = load_image(image_path)
    print(f"\nAnalyzing image: {os.path.basename(image_path)}")
    print(f"Image dimensions: {image.shape[1]}x{image.shape[0]} pixels")

    # Run standard DCT experiment
    print("\n1. Standard DCT Compression (Simple Quantization):")
    dct_simple_results = experiment_compression_quality(
        image_path, [80, 60, 40, 20, 10, 5], 'dct', perceptual=False)

    # Run perceptual DCT experiment
    print("\n2. Perceptual DCT Compression (JPEG Quantization Matrix):")
    dct_perceptual_results = experiment_compression_quality(
        image_path, [80, 60, 40, 20, 10, 5], 'dct', perceptual=True)

    # Run Haar wavelet experiment
    print("\n3. Haar Wavelet Compression:")
    wavelet_haar_results = experiment_compression_quality(
        image_path, [50, 30, 20, 10, 5, 2], 'wavelet', wavelet_type='haar')

    # Run db4 wavelet experiment
    print("\n4. DB4 Wavelet Compression (More sophisticated wavelet):")
    wavelet_db4_results = experiment_compression_quality(
        image_path, [50, 30, 20, 10, 5, 2], 'wavelet', wavelet_type='db4')

    # Artifact visualization
    print("\n5. Compression Artifact Visualization:")
    visualize_compression_artifacts(image_path, dct_quality=20, wavelet_threshold=10)
    print("\n6. Performance Comparison Plots:")

    # PSNR comparison
    plot_comparison(dct_perceptual_results, wavelet_haar_results, 'psnr',
                   "(Perceptual DCT vs Haar Wavelet)")

    # SSIM comparison
    plot_comparison(dct_perceptual_results, wavelet_haar_results, 'ssim',
                   "(Perceptual DCT vs Haar Wavelet)")

    # Execution time comparison
    plot_comparison(dct_perceptual_results, wavelet_haar_results, 'execution_time',
                   "(Perceptual DCT vs Haar Wavelet)")

    # Subjective score comparison
    plot_comparison(dct_perceptual_results, wavelet_haar_results, 'subjective_score',
                   "(Perceptual DCT vs Haar Wavelet)")

    # Compare wavelet types
    plot_comparison(wavelet_haar_results, wavelet_db4_results, 'psnr',
                   "(Haar vs DB4 Wavelet)")

    # Compare DCT quantization types
    plot_comparison(dct_simple_results, dct_perceptual_results, 'psnr',
                   "(Simple vs Perceptual DCT)")

    return {
        'dct_simple': dct_simple_results,
        'dct_perceptual': dct_perceptual_results,
        'wavelet_haar': wavelet_haar_results,
        'wavelet_db4': wavelet_db4_results
    }

#  Process Dataset with Extended Analysis
def process_dataset_extended(dataset_path, num_images=5):
    image_paths = glob.glob(os.path.join(dataset_path, '*.tif'))[:num_images]

    if not image_paths:
        print(f"No images found in {dataset_path}")
        return None

    print(f"Processing {len(image_paths)} images from {dataset_path}")
    agg_results = {
        'dct_perceptual': {
            'compression_ratio': [], 'psnr': [], 'ssim': [],
            'execution_time': [], 'subjective_score': []
        },
        'wavelet_haar': {
            'compression_ratio': [], 'psnr': [], 'ssim': [],
            'execution_time': [], 'subjective_score': []
        }
    }

    # Define which metrics are numeric
    numeric_metrics = ['compression_ratio', 'psnr', 'ssim', 'execution_time', 'subjective_score']

    # Process each image
    for i, img_path in enumerate(image_paths):
        print(f"\nProcessing image {i+1}/{len(image_paths)}: {os.path.basename(img_path)}")
        if i == 0:
            results = process_single_image_extended(img_path)
        else:
            dct_results = experiment_compression_quality(
                img_path, [80, 60, 40, 20, 10, 5], 'dct', perceptual=True)
            wavelet_results = experiment_compression_quality(
                img_path, [50, 30, 20, 10, 5, 2], 'wavelet', wavelet_type='haar')

            results = {
                'dct_perceptual': dct_results,
                'wavelet_haar': wavelet_results
            }

        # Aggregate results
        for method in ['dct_perceptual', 'wavelet_haar']:
            for metric in numeric_metrics:
                if i == 0:
                    agg_results[method][metric] = np.array(results[method][metric], dtype=np.float64)
                else:
                    agg_results[method][metric] += np.array(results[method][metric], dtype=np.float64)

    # Calculate averages
    for method in agg_results:
        for metric in numeric_metrics:
            agg_results[method][metric] /= len(image_paths)

    # Final comparison plots
    print("\nAverage Results Across Dataset:")
    plot_comparison(agg_results['dct_perceptual'], agg_results['wavelet_haar'], 'psnr',
                   f"(Average across {len(image_paths)} images)")
    plot_comparison(agg_results['dct_perceptual'], agg_results['wavelet_haar'], 'ssim',
                   f"(Average across {len(image_paths)} images)")
    plot_comparison(agg_results['dct_perceptual'], agg_results['wavelet_haar'], 'execution_time',
                   f"(Average across {len(image_paths)} images)")
    plot_comparison(agg_results['dct_perceptual'], agg_results['wavelet_haar'], 'subjective_score',
                   f"(Average across {len(image_paths)} images)")

    return agg_results

image_path = "/content/drive/MyDrive/DIA_Project/UCID1338/10.tif"
results = process_single_image_extended(image_path)
# UCID Dataset
ucid_path = "//content/drive/MyDrive/DIA_Project/UCID1338"
agg_results = process_dataset_extended(ucid_path, num_images=5)